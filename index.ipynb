{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Wv6uHfgyo-QE"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8fzC59vCG9e"
      },
      "source": [
        "Here we are taking each frame for one every second in the video and removing the similar frames using structural similarity.\n",
        "I tried with histogram similarity also but structural is working well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "WDME7T_iz7Y8"
      },
      "outputs": [],
      "source": [
        "#Extracting Frames form\n",
        "def extract_frames_per_second(video_path, output_folder):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))  # Get the FPS of the video\n",
        "    frame_count = 0\n",
        "    extracted_count = 0\n",
        "    frames = []\n",
        "    while True:\n",
        "        success, frame = cap.read()\n",
        "        if not success:\n",
        "            break\n",
        "        if frame_count % fps == 0:\n",
        "            frames.append(frame)\n",
        "            cv2.imwrite(f'{output_folder}/frame_{extracted_count:04d}.png', frame)\n",
        "            extracted_count += 1\n",
        "\n",
        "        frame_count += 1\n",
        "\n",
        "    cap.release()\n",
        "    print(f\"Extracted {extracted_count} frames (1 frame per second).\")\n",
        "    return frames\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_mqdWqyufXY",
        "outputId": "8a3dd926-b748-4b5b-b813-bc7c580a8bdc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracted 60 frames (1 frame per second).\n"
          ]
        }
      ],
      "source": [
        "frames = extract_frames_per_second(\"data/video.mp4\",\"data/frames\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "YOLO model loaded successfully.\n",
            "Layer names: ('conv_0', 'bn_0', 'leaky_1', 'conv_1', 'bn_1', 'leaky_2', 'conv_2', 'bn_2', 'leaky_3', 'conv_3', 'bn_3', 'leaky_4', 'shortcut_4', 'conv_5', 'bn_5', 'leaky_6', 'conv_6', 'bn_6', 'leaky_7', 'conv_7', 'bn_7', 'leaky_8', 'shortcut_8', 'conv_9', 'bn_9', 'leaky_10', 'conv_10', 'bn_10', 'leaky_11', 'shortcut_11', 'conv_12', 'bn_12', 'leaky_13', 'conv_13', 'bn_13', 'leaky_14', 'conv_14', 'bn_14', 'leaky_15', 'shortcut_15', 'conv_16', 'bn_16', 'leaky_17', 'conv_17', 'bn_17', 'leaky_18', 'shortcut_18', 'conv_19', 'bn_19', 'leaky_20', 'conv_20', 'bn_20', 'leaky_21', 'shortcut_21', 'conv_22', 'bn_22', 'leaky_23', 'conv_23', 'bn_23', 'leaky_24', 'shortcut_24', 'conv_25', 'bn_25', 'leaky_26', 'conv_26', 'bn_26', 'leaky_27', 'shortcut_27', 'conv_28', 'bn_28', 'leaky_29', 'conv_29', 'bn_29', 'leaky_30', 'shortcut_30', 'conv_31', 'bn_31', 'leaky_32', 'conv_32', 'bn_32', 'leaky_33', 'shortcut_33', 'conv_34', 'bn_34', 'leaky_35', 'conv_35', 'bn_35', 'leaky_36', 'shortcut_36', 'conv_37', 'bn_37', 'leaky_38', 'conv_38', 'bn_38', 'leaky_39', 'conv_39', 'bn_39', 'leaky_40', 'shortcut_40', 'conv_41', 'bn_41', 'leaky_42', 'conv_42', 'bn_42', 'leaky_43', 'shortcut_43', 'conv_44', 'bn_44', 'leaky_45', 'conv_45', 'bn_45', 'leaky_46', 'shortcut_46', 'conv_47', 'bn_47', 'leaky_48', 'conv_48', 'bn_48', 'leaky_49', 'shortcut_49', 'conv_50', 'bn_50', 'leaky_51', 'conv_51', 'bn_51', 'leaky_52', 'shortcut_52', 'conv_53', 'bn_53', 'leaky_54', 'conv_54', 'bn_54', 'leaky_55', 'shortcut_55', 'conv_56', 'bn_56', 'leaky_57', 'conv_57', 'bn_57', 'leaky_58', 'shortcut_58', 'conv_59', 'bn_59', 'leaky_60', 'conv_60', 'bn_60', 'leaky_61', 'shortcut_61', 'conv_62', 'bn_62', 'leaky_63', 'conv_63', 'bn_63', 'leaky_64', 'conv_64', 'bn_64', 'leaky_65', 'shortcut_65', 'conv_66', 'bn_66', 'leaky_67', 'conv_67', 'bn_67', 'leaky_68', 'shortcut_68', 'conv_69', 'bn_69', 'leaky_70', 'conv_70', 'bn_70', 'leaky_71', 'shortcut_71', 'conv_72', 'bn_72', 'leaky_73', 'conv_73', 'bn_73', 'leaky_74', 'shortcut_74', 'conv_75', 'bn_75', 'leaky_76', 'conv_76', 'bn_76', 'leaky_77', 'conv_77', 'bn_77', 'leaky_78', 'conv_78', 'bn_78', 'leaky_79', 'conv_79', 'bn_79', 'leaky_80', 'conv_80', 'bn_80', 'leaky_81', 'conv_81', 'permute_82', 'yolo_82', 'identity_83', 'conv_84', 'bn_84', 'leaky_85', 'upsample_85', 'concat_86', 'conv_87', 'bn_87', 'leaky_88', 'conv_88', 'bn_88', 'leaky_89', 'conv_89', 'bn_89', 'leaky_90', 'conv_90', 'bn_90', 'leaky_91', 'conv_91', 'bn_91', 'leaky_92', 'conv_92', 'bn_92', 'leaky_93', 'conv_93', 'permute_94', 'yolo_94', 'identity_95', 'conv_96', 'bn_96', 'leaky_97', 'upsample_97', 'concat_98', 'conv_99', 'bn_99', 'leaky_100', 'conv_100', 'bn_100', 'leaky_101', 'conv_101', 'bn_101', 'leaky_102', 'conv_102', 'bn_102', 'leaky_103', 'conv_103', 'bn_103', 'leaky_104', 'conv_104', 'bn_104', 'leaky_105', 'conv_105', 'permute_106', 'yolo_106')\n",
            "Output layers: ['yolo_82', 'yolo_94', 'yolo_106']\n"
          ]
        }
      ],
      "source": [
        "net = cv2.dnn.readNet(\"yolo_config/yolov3.weights\", \"yolo_config/yolov3.cfg\")\n",
        "print(\"YOLO model loaded successfully.\")\n",
        "\n",
        "# Get layer names\n",
        "layer_names = net.getLayerNames()\n",
        "print(\"Layer names:\", layer_names)\n",
        "\n",
        "classes = []\n",
        "with open(\"yolo_config/coco.names\", \"r\") as f:\n",
        "    classes = [line.strip() for line in f.readlines()]\n",
        "\n",
        "# Get output layer names\n",
        "output_layers_indices = net.getUnconnectedOutLayers()\n",
        "output_layers = [layer_names[i - 1] for i in output_layers_indices]\n",
        "print(\"Output layers:\", output_layers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'person': 0.99741817, 'umbrella': [0.9143889], 'bus': [0.6156007], 'aeroplane': 0.89126605, 'car': 0.99696904, 'surfboard': [0.6609388], 'truck': 0.9346713, 'sheep': 0.6979648, 'tie': [0.7132201], 'horse': [0.9321146]}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "output_directory = 'data/annotated_frames'\n",
        "os.makedirs(output_directory, exist_ok=True)\n",
        "\n",
        "# Dictionary to store labels and confidence scores for each frame\n",
        "frames_info = {}\n",
        "\n",
        "for i, frame in enumerate(frames):\n",
        "    height, width, channels = frame.shape\n",
        "\n",
        "    # Detecting objects\n",
        "    blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
        "    net.setInput(blob)\n",
        "    outs = net.forward(output_layers)\n",
        "\n",
        "    # Initialize dictionary for this frame\n",
        "    frame_info = {}\n",
        "\n",
        "    # Showing informations on the screen\n",
        "    class_ids = []\n",
        "    confidences = []\n",
        "    boxes = []\n",
        "    for out in outs:\n",
        "        for detection in out:\n",
        "            scores = detection[5:]\n",
        "            class_id = np.argmax(scores)\n",
        "            confidence = scores[class_id]\n",
        "            if confidence > 0.5:\n",
        "                # Object detected\n",
        "                center_x = int(detection[0] * width)\n",
        "                center_y = int(detection[1] * height)\n",
        "                w = int(detection[2] * width)\n",
        "                h = int(detection[3] * height)\n",
        "\n",
        "                # Rectangle coordinates\n",
        "                x = int(center_x - w / 2)\n",
        "                y = int(center_y - h / 2)\n",
        "\n",
        "                boxes.append([x, y, w, h])\n",
        "                confidences.append(float(confidence))\n",
        "                class_ids.append(class_id)\n",
        "\n",
        "                # Add label and confidence to the frame info dictionary\n",
        "                label = str(classes[class_id])\n",
        "                frame_info[label] = confidence\n",
        "\n",
        "    # Draw bounding boxes and labels on the frame\n",
        "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
        "    font = cv2.FONT_HERSHEY_PLAIN\n",
        "    for i in range(len(boxes)):\n",
        "        if i in indexes:\n",
        "            x, y, w, h = boxes[i]\n",
        "            label = str(classes[class_ids[i]])\n",
        "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "            cv2.putText(frame, label, (x, y + 30), font, 3, (0, 255, 0), 3)\n",
        "\n",
        "    # Save the annotated frame\n",
        "    annotated_frame_path = os.path.join(output_directory, f\"annotated_frame_{i}.jpg\")\n",
        "    cv2.imwrite(annotated_frame_path, frame)\n",
        "\n",
        "    # Store frame info in the frames_info dictionary\n",
        "    for k in frame_info.keys():\n",
        "        if k in frames_info:\n",
        "            frames_info[k] = max(frames_info[k], frame_info[k])\n",
        "        else:\n",
        "            frames_info[k] = [frame_info[k]]\n",
        "\n",
        "# Print frames_info dictionary\n",
        "print(frames_info)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'person': 0.99741817, 'car': 0.99696904, 'truck': 0.9346713, 'horse': [0.9321146], 'umbrella': [0.9143889], 'aeroplane': 0.89126605, 'tie': [0.7132201], 'sheep': 0.6979648, 'surfboard': [0.6609388], 'bus': [0.6156007]}\n"
          ]
        }
      ],
      "source": [
        "# sort the dictionary by confidence score\n",
        "sorted_frames_info = dict(sorted(frames_info.items(), key=lambda item: item[1], reverse=True))\n",
        "print(sorted_frames_info)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
