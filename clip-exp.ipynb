{"metadata":{"colab":{"name":"Inference example.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Inference on custom images","metadata":{"id":"G4jyuXtLXnPZ"}},{"cell_type":"markdown","source":"## Download code and install dependencies","metadata":{"id":"zgSUhoRppsQI"}},{"cell_type":"code","source":"!git clone https://github.com/j-min/CLIP-Caption-Reward","metadata":{"id":"6JMqvnesGnXG","colab":{"base_uri":"https://localhost:8080/"},"outputId":"477c3015-7238-4d2b-8a59-f9ff7d1da277","execution":{"iopub.status.busy":"2024-04-24T04:03:06.340802Z","iopub.execute_input":"2024-04-24T04:03:06.341057Z","iopub.status.idle":"2024-04-24T04:03:07.297419Z","shell.execute_reply.started":"2024-04-24T04:03:06.341033Z","shell.execute_reply":"2024-04-24T04:03:07.296138Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"fatal: destination path 'CLIP-Caption-Reward' already exists and is not an empty directory.\n","output_type":"stream"}]},{"cell_type":"code","source":"cd CLIP-Caption-Reward","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oFwDNTs2RwVo","outputId":"3a578958-f448-4285-cc1a-d36aba6c8863","execution":{"iopub.status.busy":"2024-04-24T04:03:07.299870Z","iopub.execute_input":"2024-04-24T04:03:07.300270Z","iopub.status.idle":"2024-04-24T04:03:07.307979Z","shell.execute_reply.started":"2024-04-24T04:03:07.300231Z","shell.execute_reply":"2024-04-24T04:03:07.306870Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/working/CLIP-Caption-Reward\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install -r requirements.txt\n!pip uninstall -y  torchtext # to bypass pt-lightning issue (https://github.com/PyTorchLightning/pytorch-lightning/issues/6415)\n!pip install -e .","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U25Mz51oRxJH","outputId":"0f94f139-a241-4030-c976-91c34c83d2d6","execution":{"iopub.status.busy":"2024-04-24T04:03:07.309311Z","iopub.execute_input":"2024-04-24T04:03:07.309667Z","iopub.status.idle":"2024-04-24T04:03:45.007824Z","shell.execute_reply.started":"2024-04-24T04:03:07.309633Z","shell.execute_reply":"2024-04-24T04:03:45.006722Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (4.39.3)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (3.10.0)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (2.1.4)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (4.66.1)\nRequirement already satisfied: scikit-image in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (0.22.0)\nRequirement already satisfied: ipywidgets in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (7.7.1)\nRequirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (0.16.6)\nCollecting bert-score (from -r requirements.txt (line 8))\n  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\nCollecting ftfy (from -r requirements.txt (line 9))\n  Downloading ftfy-6.2.0-py3-none-any.whl.metadata (7.3 kB)\nRequirement already satisfied: timm in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 10)) (0.9.16)\nCollecting lmdbdict (from -r requirements.txt (line 11))\n  Downloading lmdbdict-0.2.2-py3-none-any.whl.metadata (225 bytes)\nCollecting yacs (from -r requirements.txt (line 12))\n  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\nRequirement already satisfied: pyemd in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 13)) (1.0.0)\nRequirement already satisfied: gensim in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 14)) (4.3.2)\nCollecting pytorch-lightning==1.0.0 (from -r requirements.txt (line 15))\n  Downloading pytorch_lightning-1.0.0-py3-none-any.whl.metadata (23 kB)\nRequirement already satisfied: numpy>=1.16.4 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning==1.0.0->-r requirements.txt (line 15)) (1.26.4)\nRequirement already satisfied: torch>=1.3 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning==1.0.0->-r requirements.txt (line 15)) (2.1.2)\nRequirement already satisfied: future>=0.17.1 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning==1.0.0->-r requirements.txt (line 15)) (1.0.0)\nRequirement already satisfied: PyYAML>=5.1 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning==1.0.0->-r requirements.txt (line 15)) (6.0.1)\nRequirement already satisfied: fsspec>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning==1.0.0->-r requirements.txt (line 15)) (2024.2.0)\nRequirement already satisfied: tensorboard>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning==1.0.0->-r requirements.txt (line 15)) (2.15.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 1)) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 1)) (0.22.2)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 1)) (21.3)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 1)) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 1)) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 1)) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 1)) (0.4.3)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 3)) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 3)) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 3)) (2023.4)\nRequirement already satisfied: scipy>=1.8 in /opt/conda/lib/python3.10/site-packages (from scikit-image->-r requirements.txt (line 5)) (1.11.4)\nRequirement already satisfied: networkx>=2.8 in /opt/conda/lib/python3.10/site-packages (from scikit-image->-r requirements.txt (line 5)) (3.2.1)\nRequirement already satisfied: pillow>=9.0.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image->-r requirements.txt (line 5)) (9.5.0)\nRequirement already satisfied: imageio>=2.27 in /opt/conda/lib/python3.10/site-packages (from scikit-image->-r requirements.txt (line 5)) (2.33.1)\nRequirement already satisfied: tifffile>=2022.8.12 in /opt/conda/lib/python3.10/site-packages (from scikit-image->-r requirements.txt (line 5)) (2023.12.9)\nRequirement already satisfied: lazy_loader>=0.3 in /opt/conda/lib/python3.10/site-packages (from scikit-image->-r requirements.txt (line 5)) (0.3)\nRequirement already satisfied: ipykernel>=4.5.1 in /opt/conda/lib/python3.10/site-packages (from ipywidgets->-r requirements.txt (line 6)) (6.28.0)\nRequirement already satisfied: ipython-genutils~=0.2.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets->-r requirements.txt (line 6)) (0.2.0)\nRequirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.10/site-packages (from ipywidgets->-r requirements.txt (line 6)) (5.9.0)\nRequirement already satisfied: widgetsnbextension~=3.6.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets->-r requirements.txt (line 6)) (3.6.6)\nRequirement already satisfied: ipython>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets->-r requirements.txt (line 6)) (8.20.0)\nRequirement already satisfied: jupyterlab-widgets>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets->-r requirements.txt (line 6)) (3.0.9)\nRequirement already satisfied: Click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 7)) (8.1.7)\nRequirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 7)) (3.1.41)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 7)) (5.9.3)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 7)) (1.45.0)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 7)) (0.4.0)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 7)) (1.3.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 7)) (69.0.3)\nRequirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 7)) (1.4.4)\nRequirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 7)) (3.20.3)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from bert-score->-r requirements.txt (line 8)) (3.7.5)\nRequirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /opt/conda/lib/python3.10/site-packages (from ftfy->-r requirements.txt (line 9)) (0.2.13)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from timm->-r requirements.txt (line 10)) (0.16.2)\nCollecting lmdb (from lmdbdict->-r requirements.txt (line 11))\n  Downloading lmdb-1.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.2 kB)\nRequirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.10/site-packages (from gensim->-r requirements.txt (line 14)) (6.4.0)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb->-r requirements.txt (line 7)) (1.16.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 7)) (4.0.11)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers->-r requirements.txt (line 1)) (4.9.0)\nRequirement already satisfied: comm>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets->-r requirements.txt (line 6)) (0.2.1)\nRequirement already satisfied: debugpy>=1.6.5 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets->-r requirements.txt (line 6)) (1.8.0)\nRequirement already satisfied: jupyter-client>=6.1.12 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets->-r requirements.txt (line 6)) (7.4.9)\nRequirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets->-r requirements.txt (line 6)) (5.7.1)\nRequirement already satisfied: matplotlib-inline>=0.1 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets->-r requirements.txt (line 6)) (0.1.6)\nRequirement already satisfied: nest-asyncio in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets->-r requirements.txt (line 6)) (1.5.8)\nRequirement already satisfied: pyzmq>=24 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets->-r requirements.txt (line 6)) (24.0.1)\nRequirement already satisfied: tornado>=6.1 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets->-r requirements.txt (line 6)) (6.3.3)\nRequirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets->-r requirements.txt (line 6)) (5.1.1)\nRequirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets->-r requirements.txt (line 6)) (0.19.1)\nRequirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /opt/conda/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets->-r requirements.txt (line 6)) (3.0.42)\nRequirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets->-r requirements.txt (line 6)) (2.17.2)\nRequirement already satisfied: stack-data in /opt/conda/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets->-r requirements.txt (line 6)) (0.6.2)\nRequirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets->-r requirements.txt (line 6)) (1.2.0)\nRequirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets->-r requirements.txt (line 6)) (4.8.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers->-r requirements.txt (line 1)) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->-r requirements.txt (line 1)) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->-r requirements.txt (line 1)) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->-r requirements.txt (line 1)) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->-r requirements.txt (line 1)) (2024.2.2)\nRequirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.0->-r requirements.txt (line 15)) (1.4.0)\nRequirement already satisfied: grpcio>=1.48.2 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.0->-r requirements.txt (line 15)) (1.51.1)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.0->-r requirements.txt (line 15)) (2.26.1)\nRequirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.0->-r requirements.txt (line 15)) (1.2.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.0->-r requirements.txt (line 15)) (3.5.2)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.0->-r requirements.txt (line 15)) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.0->-r requirements.txt (line 15)) (3.0.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.3->pytorch-lightning==1.0.0->-r requirements.txt (line 15)) (1.12)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.3->pytorch-lightning==1.0.0->-r requirements.txt (line 15)) (3.1.2)\nRequirement already satisfied: notebook>=4.4.1 in /opt/conda/lib/python3.10/site-packages (from widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 6)) (6.5.4)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score->-r requirements.txt (line 8)) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score->-r requirements.txt (line 8)) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score->-r requirements.txt (line 8)) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score->-r requirements.txt (line 8)) (1.4.5)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 7)) (5.0.1)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.0.0->-r requirements.txt (line 15)) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.0.0->-r requirements.txt (line 15)) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.0.0->-r requirements.txt (line 15)) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard>=2.2.0->pytorch-lightning==1.0.0->-r requirements.txt (line 15)) (1.3.1)\nRequirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/lib/python3.10/site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets->-r requirements.txt (line 6)) (0.8.3)\nRequirement already satisfied: entrypoints in /opt/conda/lib/python3.10/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets->-r requirements.txt (line 6)) (0.4)\nRequirement already satisfied: platformdirs>=2.5 in /opt/conda/lib/python3.10/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel>=4.5.1->ipywidgets->-r requirements.txt (line 6)) (4.2.0)\nRequirement already satisfied: argon2-cffi in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 6)) (23.1.0)\nRequirement already satisfied: nbformat in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 6)) (5.9.2)\nRequirement already satisfied: nbconvert>=5 in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 6)) (6.4.5)\nRequirement already satisfied: Send2Trash>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 6)) (1.8.2)\nRequirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 6)) (0.18.0)\nRequirement already satisfied: prometheus-client in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 6)) (0.19.0)\nRequirement already satisfied: nbclassic>=0.4.7 in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 6)) (1.0.0)\nRequirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.10/site-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets->-r requirements.txt (line 6)) (0.7.0)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard>=2.2.0->pytorch-lightning==1.0.0->-r requirements.txt (line 15)) (2.1.3)\nRequirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=4.0.0->ipywidgets->-r requirements.txt (line 6)) (2.0.1)\nRequirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=4.0.0->ipywidgets->-r requirements.txt (line 6)) (2.4.1)\nRequirement already satisfied: pure-eval in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=4.0.0->ipywidgets->-r requirements.txt (line 6)) (0.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.3->pytorch-lightning==1.0.0->-r requirements.txt (line 15)) (1.3.0)\nRequirement already satisfied: jupyter-server>=1.8 in /opt/conda/lib/python3.10/site-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 6)) (2.12.5)\nRequirement already satisfied: notebook-shim>=0.2.3 in /opt/conda/lib/python3.10/site-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 6)) (0.2.3)\nRequirement already satisfied: mistune<2,>=0.8.1 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 6)) (0.8.4)\nRequirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 6)) (0.3.0)\nRequirement already satisfied: bleach in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 6)) (6.1.0)\nRequirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 6)) (1.5.0)\nRequirement already satisfied: testpath in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 6)) (0.6.0)\nRequirement already satisfied: defusedxml in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 6)) (0.7.1)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 6)) (4.12.2)\nRequirement already satisfied: nbclient<0.6.0,>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 6)) (0.5.13)\nRequirement already satisfied: fastjsonschema in /opt/conda/lib/python3.10/site-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 6)) (2.19.1)\nRequirement already satisfied: jsonschema>=2.6 in /opt/conda/lib/python3.10/site-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 6)) (4.20.0)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.0.0->-r requirements.txt (line 15)) (0.5.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard>=2.2.0->pytorch-lightning==1.0.0->-r requirements.txt (line 15)) (3.2.2)\nRequirement already satisfied: argon2-cffi-bindings in /opt/conda/lib/python3.10/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 6)) (21.2.0)\nRequirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 6)) (23.2.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 6)) (2023.12.1)\nRequirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 6)) (0.32.1)\nRequirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 6)) (0.16.2)\nRequirement already satisfied: anyio>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 6)) (4.2.0)\nRequirement already satisfied: jupyter-events>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 6)) (0.9.0)\nRequirement already satisfied: jupyter-server-terminals in /opt/conda/lib/python3.10/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 6)) (0.5.1)\nRequirement already satisfied: overrides in /opt/conda/lib/python3.10/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 6)) (7.4.0)\nRequirement already satisfied: websocket-client in /opt/conda/lib/python3.10/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 6)) (1.7.0)\nRequirement already satisfied: cffi>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 6)) (1.16.0)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 6)) (2.5)\nRequirement already satisfied: webencodings in /opt/conda/lib/python3.10/site-packages (from bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 6)) (0.5.1)\nRequirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 6)) (1.3.0)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 6)) (2.21)\nRequirement already satisfied: python-json-logger>=2.0.4 in /opt/conda/lib/python3.10/site-packages (from jupyter-events>=0.9.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 6)) (2.0.7)\nRequirement already satisfied: rfc3339-validator in /opt/conda/lib/python3.10/site-packages (from jupyter-events>=0.9.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 6)) (0.1.4)\nRequirement already satisfied: rfc3986-validator>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from jupyter-events>=0.9.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 6)) (0.1.1)\nRequirement already satisfied: fqdn in /opt/conda/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 6)) (1.5.1)\nRequirement already satisfied: isoduration in /opt/conda/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 6)) (20.11.0)\nRequirement already satisfied: jsonpointer>1.13 in /opt/conda/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 6)) (2.4)\nRequirement already satisfied: uri-template in /opt/conda/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 6)) (1.3.0)\nRequirement already satisfied: webcolors>=1.11 in /opt/conda/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 6)) (1.13)\nRequirement already satisfied: arrow>=0.15.0 in /opt/conda/lib/python3.10/site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 6)) (1.3.0)\nRequirement already satisfied: types-python-dateutil>=2.8.10 in /opt/conda/lib/python3.10/site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 6)) (2.8.19.20240106)\nDownloading pytorch_lightning-1.0.0-py3-none-any.whl (510 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.4/510.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading ftfy-6.2.0-py3-none-any.whl (54 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.4/54.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading lmdbdict-0.2.2-py3-none-any.whl (6.0 kB)\nDownloading yacs-0.1.8-py3-none-any.whl (14 kB)\nDownloading lmdb-1.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (299 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.2/299.2 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: lmdb, yacs, lmdbdict, ftfy, pytorch-lightning, bert-score\n  Attempting uninstall: pytorch-lightning\n    Found existing installation: pytorch-lightning 2.2.2\n    Uninstalling pytorch-lightning-2.2.2:\n      Successfully uninstalled pytorch-lightning-2.2.2\nSuccessfully installed bert-score-0.3.13 ftfy-6.2.0 lmdb-1.4.1 lmdbdict-0.2.2 pytorch-lightning-1.0.0 yacs-0.1.8\nFound existing installation: torchtext 0.16.2\nUninstalling torchtext-0.16.2:\n  Successfully uninstalled torchtext-0.16.2\nObtaining file:///kaggle/working/CLIP-Caption-Reward\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hInstalling collected packages: captioning\n  Running setup.py develop for captioning\nSuccessfully installed captioning-0.0.1\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Import packages","metadata":{"id":"HlGNNTLkTZtU"}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nimport numpy as np\n\nimport json\n\nimport captioning.utils.opts as opts\nimport captioning.models as models\nimport captioning.utils.misc as utils\n\nimport pytorch_lightning as pl\n\n# Checkpoint class\nclass ModelCheckpoint(pl.callbacks.ModelCheckpoint):\n\n    def on_keyboard_interrupt(self, trainer, pl_module):\n        # Save model when keyboard interrupt\n        filepath = os.path.join(self.dirpath, self.prefix + 'interrupt.ckpt')\n        self._save_model(filepath)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5YD_6lhfSeiu","outputId":"d0a11c3d-17fc-4238-db65-ac7b3019c4ed","execution":{"iopub.status.busy":"2024-04-24T04:03:45.010167Z","iopub.execute_input":"2024-04-24T04:03:45.010479Z","iopub.status.idle":"2024-04-24T04:04:13.145367Z","shell.execute_reply.started":"2024-04-24T04:03:45.010452Z","shell.execute_reply":"2024-04-24T04:04:13.144378Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"meshed-memory-transformer not installed; please run `pip install git+https://github.com/ruotianluo/meshed-memory-transformer.git`\n","output_type":"stream"},{"name":"stderr","text":"2024-04-24 04:03:59.736942: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-24 04:03:59.737069: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-24 04:03:59.986863: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install git+https://github.com/ruotianluo/meshed-memory-transformer.git","metadata":{"execution":{"iopub.status.busy":"2024-04-24T04:04:13.146507Z","iopub.execute_input":"2024-04-24T04:04:13.146798Z","iopub.status.idle":"2024-04-24T04:04:29.184858Z","shell.execute_reply.started":"2024-04-24T04:04:13.146774Z","shell.execute_reply":"2024-04-24T04:04:29.183751Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Collecting git+https://github.com/ruotianluo/meshed-memory-transformer.git\n  Cloning https://github.com/ruotianluo/meshed-memory-transformer.git to /tmp/pip-req-build-t9fn5tx8\n  Running command git clone --filter=blob:none --quiet https://github.com/ruotianluo/meshed-memory-transformer.git /tmp/pip-req-build-t9fn5tx8\n  Resolved https://github.com/ruotianluo/meshed-memory-transformer.git to commit f74657320a947ad1d9868de6a6c757dbac341eda\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: meshed_memory_transformer\n  Building wheel for meshed_memory_transformer (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for meshed_memory_transformer: filename=meshed_memory_transformer-0.0.1-py3-none-any.whl size=39521 sha256=16e920adbc0f9e543f0a59dd9c9ca690d8c87196ea220a558772b62f3b41da3e\n  Stored in directory: /tmp/pip-ephem-wheel-cache-haye34eb/wheels/98/10/2e/74211626a660b85e2332e7884db384c5aca1894d57fb1eddc2\nSuccessfully built meshed_memory_transformer\nInstalling collected packages: meshed_memory_transformer\nSuccessfully installed meshed_memory_transformer-0.0.1\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Device and model configurations","metadata":{"id":"Xz69U1BuU6je"}},{"cell_type":"code","source":"device = 'cuda' #@param [\"cuda\", \"cpu\"] {allow-input: true}\n\nreward = 'mle' #@param [\"mle\", \"cider\", \"clips\", \"cider_clips\", \"clips_grammar\"] {allow-input: true}\n\nif reward == 'mle':\n    cfg = f'./configs/phase1/clipRN50_{reward}.yml'\nelse:\n    cfg = f'./configs/phase2/clipRN50_{reward}.yml'\n\nprint(\"Loading cfg from\", cfg)\n\nopt = opts.parse_opt(parse=False, cfg=cfg)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_V2zNYY9TdEg","outputId":"efe1e206-a1ce-480c-af46-2a384f5f0a2e","execution":{"iopub.status.busy":"2024-04-24T04:37:05.173571Z","iopub.execute_input":"2024-04-24T04:37:05.173911Z","iopub.status.idle":"2024-04-24T04:37:05.189406Z","shell.execute_reply.started":"2024-04-24T04:37:05.173887Z","shell.execute_reply":"2024-04-24T04:37:05.188462Z"},"trusted":true},"execution_count":78,"outputs":[{"name":"stdout","text":"Loading cfg from ./configs/phase1/clipRN50_mle.yml\nWarning: key input_clipscore_vis_dir not in args\nWarning: key N_enc not in args\nWarning: key N_dec not in args\nWarning: key d_model not in args\nWarning: key d_ff not in args\nWarning: key num_att_heads not in args\nWarning: key dropout not in args\nWarning: key REFORWARD not in args\nWarning: key precision not in args\n","output_type":"stream"}]},{"cell_type":"code","source":"# print(opt)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T04:37:05.788964Z","iopub.execute_input":"2024-04-24T04:37:05.789808Z","iopub.status.idle":"2024-04-24T04:37:05.793462Z","shell.execute_reply.started":"2024-04-24T04:37:05.789775Z","shell.execute_reply":"2024-04-24T04:37:05.792629Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"markdown","source":"# Download pretrained checkpoint","metadata":{"id":"eS7jCJ6_TMRP"}},{"cell_type":"code","source":"!pip install gdown","metadata":{"execution":{"iopub.status.busy":"2024-04-24T04:04:29.214155Z","iopub.execute_input":"2024-04-24T04:04:29.214416Z","iopub.status.idle":"2024-04-24T04:04:41.772882Z","shell.execute_reply.started":"2024-04-24T04:04:29.214393Z","shell.execute_reply":"2024-04-24T04:04:41.771924Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Collecting gdown\n  Downloading gdown-5.1.0-py3-none-any.whl.metadata (5.7 kB)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown) (4.12.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from gdown) (3.13.1)\nRequirement already satisfied: requests[socks] in /opt/conda/lib/python3.10/site-packages (from gdown) (2.31.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from gdown) (4.66.1)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2024.2.2)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\nDownloading gdown-5.1.0-py3-none-any.whl (17 kB)\nInstalling collected packages: gdown\nSuccessfully installed gdown-5.1.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import gdown","metadata":{"id":"3WWSm2x7Si1S","execution":{"iopub.status.busy":"2024-04-24T04:04:41.774279Z","iopub.execute_input":"2024-04-24T04:04:41.774586Z","iopub.status.idle":"2024-04-24T04:04:42.026936Z","shell.execute_reply.started":"2024-04-24T04:04:41.774557Z","shell.execute_reply":"2024-04-24T04:04:42.025943Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"if reward == \"mle\":\n  url = \"https://drive.google.com/drive/folders/1hfHWDn5iXsdjB63E5zdZBAoRLWHQC3LD\"\nelif reward == \"cider\":\n  url = \"https://drive.google.com/drive/folders/1MnSmCd8HFnBvQq_4K-q4vsVkzEw0OIOs\"\nelif reward == \"clips\":\n  url = \"https://drive.google.com/drive/folders/1toceycN-qilHsbYjKalBLtHJck1acQVe\"\nelif reward == \"cider_clips\":\n  url = \"https://drive.google.com/drive/folders/1toceycN-qilHsbYjKalBLtHJck1acQVe\"\nelif reward == \"clips_grammar\":\n  url = \"https://drive.google.com/drive/folders/1nSX9aS7pPK4-OTHYtsUD_uEkwIQVIV7W\"\ngdown.download_folder(url, quiet=True, use_cookies=False, output=\"save/\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5_aLIn4nRs88","outputId":"d94e1753-5dfb-48aa-ceb6-c20c8f3bdaf2","execution":{"iopub.status.busy":"2024-04-24T04:37:10.174467Z","iopub.execute_input":"2024-04-24T04:37:10.174870Z","iopub.status.idle":"2024-04-24T04:37:16.904037Z","shell.execute_reply.started":"2024-04-24T04:37:10.174842Z","shell.execute_reply":"2024-04-24T04:37:16.903058Z"},"trusted":true},"execution_count":80,"outputs":[{"execution_count":80,"output_type":"execute_result","data":{"text/plain":"['save/clipRN50_mle/clipRN50_mle-last.ckpt']"},"metadata":{}}]},{"cell_type":"markdown","source":"# Load vocabulary","metadata":{"id":"yNb_45vLU75O"}},{"cell_type":"code","source":"# url for the videos\n# url = \"https://drive.google.com/drive/folders/1PfKgVYgj8kzOCctI67deAa3Aozpn1ZeL\"\n# gdown.download_folder(url, quiet=True, use_cookies=False, output=\"data/\")\n\nurl = \"https://drive.google.com/uc?id=1HNRE1MYO9wxmtMHLC8zURraoNFu157Dp\"\ngdown.download(url, quiet=True, use_cookies=False, output=\"data/\")","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"-7WigcUaVD0G","outputId":"61f983fa-c33c-46eb-9803-81828b8c4b52","execution":{"iopub.status.busy":"2024-04-24T04:31:51.149589Z","iopub.execute_input":"2024-04-24T04:31:51.150253Z","iopub.status.idle":"2024-04-24T04:31:55.470657Z","shell.execute_reply.started":"2024-04-24T04:31:51.150219Z","shell.execute_reply":"2024-04-24T04:31:55.469669Z"},"trusted":true},"execution_count":63,"outputs":[{"execution_count":63,"output_type":"execute_result","data":{"text/plain":"'data/cocotalk.json'"},"metadata":{}}]},{"cell_type":"code","source":"# !rm data/view\\?usp\\=drive_link","metadata":{"execution":{"iopub.status.busy":"2024-04-24T01:08:08.808503Z","iopub.execute_input":"2024-04-24T01:08:08.809201Z","iopub.status.idle":"2024-04-24T01:08:09.899660Z","shell.execute_reply.started":"2024-04-24T01:08:08.809154Z","shell.execute_reply":"2024-04-24T01:08:09.898180Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"dict_json = json.load(open('./data/cocotalk.json'))\nprint(dict_json.keys())\n\nix_to_word = dict_json['ix_to_word']\nvocab_size = len(ix_to_word)\nprint('vocab size:', vocab_size)\n\nseq_length = 1\n\nopt.vocab_size = vocab_size\nopt.seq_length = seq_length","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NPx1ISo8U-nU","outputId":"f71126e6-b6b8-4e9d-adef-3a3b0be64bf5","execution":{"iopub.status.busy":"2024-04-24T04:37:44.778798Z","iopub.execute_input":"2024-04-24T04:37:44.779126Z","iopub.status.idle":"2024-04-24T04:37:44.971094Z","shell.execute_reply.started":"2024-04-24T04:37:44.779102Z","shell.execute_reply":"2024-04-24T04:37:44.970115Z"},"trusted":true},"execution_count":81,"outputs":[{"name":"stdout","text":"dict_keys(['ix_to_word', 'images'])\nvocab size: 9487\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Load Model checkpoint","metadata":{"id":"8UklpUrRWF6z"}},{"cell_type":"code","source":"opt.batch_size = 1\nopt.vocab = ix_to_word\n# opt.use_grammar = False\n\nmodel = models.setup(opt)\ndel opt.vocab\n\nckpt_path = opt.checkpoint_path + '-last.ckpt'\n\nprint(\"Loading checkpoint from\", ckpt_path)\nraw_state_dict = torch.load(\n    ckpt_path,\n    map_location=device)\n\nstrict = True\n\nstate_dict = raw_state_dict['state_dict']\n\nif '_vocab' in state_dict:\n    model.vocab = utils.deserialize(state_dict['_vocab'])\n    del state_dict['_vocab']\nelif strict:\n    raise KeyError\nif '_opt' in state_dict:\n    saved_model_opt = utils.deserialize(state_dict['_opt'])\n    del state_dict['_opt']\n    # Make sure the saved opt is compatible with the curren topt\n    need_be_same = [\"caption_model\",\n                    \"rnn_type\", \"rnn_size\", \"num_layers\"]\n    for checkme in need_be_same:\n        if getattr(saved_model_opt, checkme) in ['updown', 'topdown'] and \\\n                getattr(opt, checkme) in ['updown', 'topdown']:\n            continue\n        assert getattr(saved_model_opt, checkme) == getattr(\n            opt, checkme), \"Command line argument and saved model disagree on '%s' \" % checkme\nelif strict:\n    raise KeyError\nres = model.load_state_dict(state_dict, strict)\nprint(res)\n\nmodel = model.to(device)\nmodel.eval();","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r7HGZL9_V_fR","outputId":"cdba141b-badd-49f9-95af-7fb20c544713","execution":{"iopub.status.busy":"2024-04-24T04:37:45.490717Z","iopub.execute_input":"2024-04-24T04:37:45.491043Z","iopub.status.idle":"2024-04-24T04:37:47.095616Z","shell.execute_reply.started":"2024-04-24T04:37:45.491017Z","shell.execute_reply":"2024-04-24T04:37:47.094726Z"},"trusted":true},"execution_count":82,"outputs":[{"name":"stdout","text":"Loading checkpoint from save/clipRN50_mle/clipRN50_mle-last.ckpt\n<All keys matched successfully>\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Load CLIP image encoder","metadata":{"id":"5gqyl28EXF0U"}},{"cell_type":"code","source":"import clip\nfrom torchvision.transforms import Compose, Resize, CenterCrop, ToTensor, Normalize\nfrom PIL import Image\nfrom timm.models.vision_transformer import resize_pos_embed\n\nclip_model, clip_transform = clip.load(\"RN50\", jit=False, device=device)\n\npreprocess = Compose([\n    Resize((448, 448), interpolation=Image.BICUBIC),\n    CenterCrop((448, 448)),\n    ToTensor()\n])\n\nimage_mean = torch.Tensor([0.48145466, 0.4578275, 0.40821073]).to(device).reshape(3, 1, 1)\nimage_std = torch.Tensor([0.26862954, 0.26130258, 0.27577711]).to(device).reshape(3, 1, 1)\n\nnum_patches = 196 #600 * 1000 // 32 // 32\npos_embed = nn.Parameter(torch.zeros(1, num_patches + 1, clip_model.visual.attnpool.positional_embedding.shape[-1],  device=device),)\npos_embed.weight = resize_pos_embed(clip_model.visual.attnpool.positional_embedding.unsqueeze(0), pos_embed)\nclip_model.visual.attnpool.positional_embedding = pos_embed","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9E43zTOYXEfy","outputId":"0bf33bb6-af15-44da-df4e-c6196a064c2b","execution":{"iopub.status.busy":"2024-04-24T04:37:47.642105Z","iopub.execute_input":"2024-04-24T04:37:47.642637Z","iopub.status.idle":"2024-04-24T04:37:50.666424Z","shell.execute_reply.started":"2024-04-24T04:37:47.642608Z","shell.execute_reply":"2024-04-24T04:37:50.665465Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"markdown","source":"# Extract Visual feature","metadata":{"id":"-TMkx3chXYZy"}},{"cell_type":"code","source":"# !pip install ipython","metadata":{"execution":{"iopub.status.busy":"2024-04-24T02:53:39.458333Z","iopub.execute_input":"2024-04-24T02:53:39.459038Z","iopub.status.idle":"2024-04-24T02:53:51.845867Z","shell.execute_reply.started":"2024-04-24T02:53:39.459004Z","shell.execute_reply":"2024-04-24T02:53:51.844692Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Requirement already satisfied: ipython in /opt/conda/lib/python3.10/site-packages (8.20.0)\nRequirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from ipython) (5.1.1)\nRequirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.10/site-packages (from ipython) (0.19.1)\nRequirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.10/site-packages (from ipython) (0.1.6)\nRequirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /opt/conda/lib/python3.10/site-packages (from ipython) (3.0.42)\nRequirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from ipython) (2.17.2)\nRequirement already satisfied: stack-data in /opt/conda/lib/python3.10/site-packages (from ipython) (0.6.2)\nRequirement already satisfied: traitlets>=5 in /opt/conda/lib/python3.10/site-packages (from ipython) (5.9.0)\nRequirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from ipython) (1.2.0)\nRequirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.10/site-packages (from ipython) (4.8.0)\nRequirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/lib/python3.10/site-packages (from jedi>=0.16->ipython) (0.8.3)\nRequirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.10/site-packages (from pexpect>4.3->ipython) (0.7.0)\nRequirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython) (0.2.13)\nRequirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython) (2.0.1)\nRequirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython) (2.4.1)\nRequirement already satisfied: pure-eval in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython) (0.2.2)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"img_path = './assets/COCO_val2014_000000462565.jpeg'\n# from IPython.display import Image as show_image\n# show_image(img_path)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":863},"id":"yyi2O_q3XLbv","outputId":"8c6400c4-6ab7-4f92-c502-c59274f27b40","execution":{"iopub.status.busy":"2024-04-24T04:06:01.710315Z","iopub.execute_input":"2024-04-24T04:06:01.711027Z","iopub.status.idle":"2024-04-24T04:06:01.715358Z","shell.execute_reply.started":"2024-04-24T04:06:01.710994Z","shell.execute_reply":"2024-04-24T04:06:01.714200Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"with torch.no_grad():\n    image = preprocess(Image.open( img_path ).convert(\"RGB\"))\n    image = torch.tensor(np.stack([image])).to(device)\n    image -= image_mean\n    image /= image_std\n\n    tmp_att, tmp_fc = clip_model.encode_image(image)\n    tmp_att = tmp_att[0].permute(1, 2, 0)\n    tmp_fc = tmp_fc[0]\n\n    att_feat = tmp_att\n    fc_feat = tmp_fc","metadata":{"id":"L9kRJdMTXI5y","execution":{"iopub.status.busy":"2024-04-24T04:06:01.976642Z","iopub.execute_input":"2024-04-24T04:06:01.976934Z","iopub.status.idle":"2024-04-24T04:06:03.517588Z","shell.execute_reply.started":"2024-04-24T04:06:01.976910Z","shell.execute_reply":"2024-04-24T04:06:03.516728Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"# Generate caption","metadata":{"id":"JBdYyHmdXQhe"}},{"cell_type":"code","source":"# Inference configurations\neval_kwargs = {}\neval_kwargs.update(vars(opt))\n\nverbose = eval_kwargs.get('verbose', True)\nverbose_beam = eval_kwargs.get('verbose_beam', 0)\nverbose_loss = eval_kwargs.get('verbose_loss', 1)\n\n# dataset = eval_kwargs.get('dataset', 'coco')\nbeam_size = eval_kwargs.get('beam_size', 1)\nsample_n = eval_kwargs.get('sample_n', 1)\nremove_bad_endings = eval_kwargs.get('remove_bad_endings', 0)\n\nwith torch.no_grad():\n    fc_feats = torch.zeros((1,0)).to(device)\n    att_feats = att_feat.view(1, 196, 2048).float().to(device)\n    att_masks = None\n\n    # forward the model to also get generated samples for each image\n    # Only leave one feature for each image, in case duplicate sample\n    tmp_eval_kwargs = eval_kwargs.copy()\n    tmp_eval_kwargs.update({'sample_n': 1})\n    seq, seq_logprobs = model(\n        fc_feats, att_feats, att_masks, opt=tmp_eval_kwargs, mode='sample')\n    seq = seq.data\n\n    sents = utils.decode_sequence(model.vocab, seq)\n\nprint(sents)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QL8GAcqaXPaT","outputId":"26a27739-a7f4-47c8-938d-48c438f204c3","execution":{"iopub.status.busy":"2024-04-24T04:06:03.520089Z","iopub.execute_input":"2024-04-24T04:06:03.520461Z","iopub.status.idle":"2024-04-24T04:06:04.591708Z","shell.execute_reply.started":"2024-04-24T04:06:03.520429Z","shell.execute_reply":"2024-04-24T04:06:04.590799Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"['a group of people riding bikes down a city street']\n","output_type":"stream"}]},{"cell_type":"code","source":"import cv2\nimport matplotlib.pyplot as plt","metadata":{"id":"QCY2SawWNCAi","execution":{"iopub.status.busy":"2024-04-24T04:06:10.407358Z","iopub.execute_input":"2024-04-24T04:06:10.408079Z","iopub.status.idle":"2024-04-24T04:06:10.954999Z","shell.execute_reply.started":"2024-04-24T04:06:10.408047Z","shell.execute_reply":"2024-04-24T04:06:10.954224Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def nograd(frame):\n    with torch.no_grad():\n        pilimg = Image.fromarray(frame)\n        image = preprocess(pilimg).convert(\"RGB\")\n        image = torch.tensor(np.stack([image])).to(device)\n        image -= image_mean\n        image /= image_std\n\n        tmp_att, tmp_fc = clip_model.encode_image(image)\n        tmp_att = tmp_att[0].permute(1, 2, 0)\n        tmp_fc = tmp_fc[0]\n\n        att_feat = tmp_att\n        fc_feat = tmp_fc\n    return image","metadata":{"execution":{"iopub.status.busy":"2024-04-24T04:20:01.194900Z","iopub.execute_input":"2024-04-24T04:20:01.195295Z","iopub.status.idle":"2024-04-24T04:20:01.201966Z","shell.execute_reply.started":"2024-04-24T04:20:01.195262Z","shell.execute_reply":"2024-04-24T04:20:01.200539Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"from torchvision.transforms.functional import to_pil_image\n","metadata":{"execution":{"iopub.status.busy":"2024-04-24T04:22:02.213739Z","iopub.execute_input":"2024-04-24T04:22:02.214660Z","iopub.status.idle":"2024-04-24T04:22:02.219224Z","shell.execute_reply.started":"2024-04-24T04:22:02.214620Z","shell.execute_reply":"2024-04-24T04:22:02.218095Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"def nograd(frame):\n    with torch.no_grad():\n        # Convert numpy array to PIL Image\n        pil_image = Image.fromarray(frame)\n        \n        # Apply preprocessing\n        image = preprocess(pil_image)\n        \n        # Convert the preprocessed image back to PIL Image\n        image_pil = to_pil_image(image)\n        \n        # Convert PIL Image to tensor\n        image_tensor = ToTensor()(image_pil)\n        \n        image_tensor = torch.tensor(np.stack([image_tensor])).to(device)\n        image_tensor -= image_mean\n        image_tensor /= image_std\n\n        tmp_att, tmp_fc = clip_model.encode_image(image_tensor)\n        tmp_att = tmp_att[0].permute(1, 2, 0)\n        tmp_fc = tmp_fc[0]\n\n        att_feat = tmp_att\n        fc_feat = tmp_fc\n    return image_tensor\n","metadata":{"execution":{"iopub.status.busy":"2024-04-24T04:22:45.533576Z","iopub.execute_input":"2024-04-24T04:22:45.534399Z","iopub.status.idle":"2024-04-24T04:22:45.540950Z","shell.execute_reply.started":"2024-04-24T04:22:45.534367Z","shell.execute_reply":"2024-04-24T04:22:45.539921Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"def gen_captions():\n    # Inference configurations\n    eval_kwargs = {}\n    eval_kwargs.update(vars(opt))\n\n    verbose = eval_kwargs.get('verbose', True)\n    verbose_beam = eval_kwargs.get('verbose_beam', 0)\n    verbose_loss = eval_kwargs.get('verbose_loss', 1)\n\n    # dataset = eval_kwargs.get('dataset', 'coco')\n    beam_size = eval_kwargs.get('beam_size', 1)\n    sample_n = eval_kwargs.get('sample_n', 1)\n    remove_bad_endings = eval_kwargs.get('remove_bad_endings', 0)\n\n    with torch.no_grad():\n        fc_feats = torch.zeros((1,0)).to(device)\n        att_feats = att_feat.view(1, 196, 2048).float().to(device)\n        att_masks = None\n\n        # forward the model to also get generated samples for each image\n        # Only leave one feature for each image, in case duplicate sample\n        tmp_eval_kwargs = eval_kwargs.copy()\n        tmp_eval_kwargs.update({'sample_n': 1})\n        seq, seq_logprobs = model(\n            fc_feats, att_feats, att_masks, opt=tmp_eval_kwargs, mode='sample')\n        seq = seq.data\n\n        sents = utils.decode_sequence(model.vocab, seq)\n\n    return sents","metadata":{"execution":{"iopub.status.busy":"2024-04-24T04:22:45.923363Z","iopub.execute_input":"2024-04-24T04:22:45.923653Z","iopub.status.idle":"2024-04-24T04:22:45.931520Z","shell.execute_reply.started":"2024-04-24T04:22:45.923629Z","shell.execute_reply":"2024-04-24T04:22:45.930585Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"#Extracting Frames form\nres = []\ndef extract_frames_per_second(video_path, output_folder):\n    cap = cv2.VideoCapture(video_path)\n    fps = int(cap.get(cv2.CAP_PROP_FPS))  # Get the FPS of the video\n    print(\"fps:\", fps)\n    frame_count = 0\n    extracted_count = 0\n    ii = 0\n    # if not os.path.exists(output_folder):\n    #     os.makedirs(output_folder)\n    while True:\n        ii += 1\n        if ii%50==0:\n            print(\"ii:\", ii)\n        success, frame = cap.read()\n#         print(\"fr type:\", type(frame))\n        if not success:\n            break\n        if frame_count % fps == 0:\n            # cv2.imwrite(f'{output_folder}/frame_{extracted_count:04d}.png', frame)\n            with torch.no_grad():\n                # Convert numpy array to PIL Image\n                pil_image = Image.fromarray(frame)\n\n                # Apply preprocessing\n                image = preprocess(pil_image)\n\n                # Convert the preprocessed image back to PIL Image\n                image_pil = to_pil_image(image)\n\n                # Convert PIL Image to tensor\n                image_tensor = ToTensor()(image_pil)\n\n                image_tensor = torch.tensor(np.stack([image_tensor])).to(device)\n                image_tensor -= image_mean\n                image_tensor /= image_std\n\n                tmp_att, tmp_fc = clip_model.encode_image(image_tensor)\n                tmp_att = tmp_att[0].permute(1, 2, 0)\n                tmp_fc = tmp_fc[0]\n\n                att_feat = tmp_att\n                fc_feat = tmp_fc\n#             return image_tensor\n            \n            eval_kwargs = {}\n            eval_kwargs.update(vars(opt))\n\n            verbose = eval_kwargs.get('verbose', True)\n            verbose_beam = eval_kwargs.get('verbose_beam', 0)\n            verbose_loss = eval_kwargs.get('verbose_loss', 1)\n\n            # dataset = eval_kwargs.get('dataset', 'coco')\n            beam_size = eval_kwargs.get('beam_size', 1)\n            sample_n = eval_kwargs.get('sample_n', 1)\n            remove_bad_endings = eval_kwargs.get('remove_bad_endings', 0)\n\n            with torch.no_grad():\n                fc_feats = torch.zeros((1,0)).to(device)\n                att_feats = att_feat.view(1, 196, 2048).float().to(device)\n                att_masks = None\n\n                # forward the model to also get generated samples for each image\n                # Only leave one feature for each image, in case duplicate sample\n                tmp_eval_kwargs = eval_kwargs.copy()\n                tmp_eval_kwargs.update({'sample_n': 1})\n                seq, seq_logprobs = model(\n                    fc_feats, att_feats, att_masks, opt=tmp_eval_kwargs, mode='sample')\n                seq = seq.data\n\n                sents = utils.decode_sequence(model.vocab, seq)\n\n            res.append(sents[0])\n            \n#             out = gen_captions()\n#             res.append(out)\n            extracted_count += 1\n\n        frame_count += 1\n    print(*res, sep='\\n')\n    cap.release()\n    print(f\"Extracted {extracted_count} frames (1 frame per second).\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-24T06:19:44.061432Z","iopub.execute_input":"2024-04-24T06:19:44.062261Z","iopub.status.idle":"2024-04-24T06:19:44.077540Z","shell.execute_reply.started":"2024-04-24T06:19:44.062225Z","shell.execute_reply":"2024-04-24T06:19:44.076514Z"},"trusted":true},"execution_count":97,"outputs":[]},{"cell_type":"code","source":"extract_frames_per_second(\"./data/AD/00000n262-30000157739826_050_mezzCrop-high.mp4\",\"\")","metadata":{"execution":{"iopub.status.busy":"2024-04-24T06:20:33.095902Z","iopub.execute_input":"2024-04-24T06:20:33.096256Z","iopub.status.idle":"2024-04-24T06:20:48.220415Z","shell.execute_reply.started":"2024-04-24T06:20:33.096227Z","shell.execute_reply":"2024-04-24T06:20:48.219381Z"},"trusted":true},"execution_count":99,"outputs":[{"name":"stdout","text":"fps: 24\nii: 50\nii: 100\nii: 150\nii: 200\nii: 250\nii: 300\nii: 350\nii: 400\nii: 450\nii: 500\nii: 550\nii: 600\nii: 650\nii: 700\nii: 750\nii: 800\nii: 850\nii: 900\nii: 950\nii: 1000\nii: 1050\nii: 1100\nii: 1150\nii: 1200\nii: 1250\nii: 1300\nii: 1350\nii: 1400\nii: 1450\na dark night with a dark background and a dark background\na woman in a dress is posing for a picture\na woman with a hat and a scarf on\na man brushing his teeth in front of a tree\na black and white photo of a tree with a branch in the background\na man laying on a bed with a dog\na woman holding a stuffed animal in her hand\na sign that says UNK on it is in the sky\na woman in a dress and a tie is smiling\na woman in a hat and scarf sitting in front of a tree\na woman riding on the back of a motorcycle\na woman riding on the back of a motorcycle\na boat traveling down a wet road near a beach\na black and white photo of a sign and a building\na person riding a motorcycle on a beach\na woman is eating food with a fork\na black and white photo of a bird flying over water\na sign that says slow on it is in front of a house\na woman with long hair is brushing her teeth\na woman with a toothbrush in her mouth\na woman in a hat and scarf is posing for a picture\na woman in a hat and a hat posing for a picture\na young woman is laying down on a bed\na woman in a white shirt and tie standing next to a tree\na man riding a bike with a dog on a leash\na woman in a white dress shirt and tie\na woman in a coat and hat posing for a picture\na woman in a hat and a tie is smiling\na young girl with a coat and tie on\na man sitting on a motor scooter on a beach\na stop sign with a black and white border and a black and white photo of\na woman is riding a motorcycle with a car\na woman riding a motorcycle down a street\na woman with long hair and a long hair\na woman with a black and white scarf holding a frisbee\na woman with a white shirt and a tie\na white foam container sitting next to a white plate\na UNK written on a ship is in the water\na dog is in the snow on a slope\na close up of a person with a hair dryer\na piece of paper with a quote on it\na woman with a white shirt and a tie\na man in a white dress shirt and tie\na woman with long hair and a hair dryer\na close up of a person wearing a shirt and tie\na woman with a UNK on her face is brushing her teeth\na woman with a tattoo on her head\na train is parked on the tracks in a train station\na train is traveling down the tracks at night\na woman with a toothbrush in her mouth\na group of people walking up a ramp on a bridge\na black and white photo of people on a boat\na couple of people sitting on a bench\na man and woman are kissing while kissing\na man holding a plaque with a picture of a UNK on it\na suitcase with a picture of a UNK on it\na suitcase sitting on the ground in front of a building\na man and woman riding on a motorcycle\na man and a woman sitting on a motorcycle\na motorcycle with graffiti written on it is parked on the street\na person riding a motorcycle with a sign on the back\na dark night with a dark background and a dark background\na dark night with a dark background and a dark background\na woman in a dress is posing for a picture\na woman with a hat and a scarf on\na man brushing his teeth in front of a tree\na black and white photo of a tree with a branch in the background\na man laying on a bed with a dog\na woman holding a stuffed animal in her hand\na sign that says UNK on it is in the sky\na woman in a dress and a tie is smiling\na woman in a hat and scarf sitting in front of a tree\na woman riding on the back of a motorcycle\na woman riding on the back of a motorcycle\na boat traveling down a wet road near a beach\na black and white photo of a sign and a building\na person riding a motorcycle on a beach\na woman is eating food with a fork\na black and white photo of a bird flying over water\na sign that says slow on it is in front of a house\na woman with long hair is brushing her teeth\na woman with a toothbrush in her mouth\na woman in a hat and scarf is posing for a picture\na woman in a hat and a hat posing for a picture\na young woman is laying down on a bed\na woman in a white shirt and tie standing next to a tree\na man riding a bike with a dog on a leash\na woman in a white dress shirt and tie\na woman in a coat and hat posing for a picture\na woman in a hat and a tie is smiling\na young girl with a coat and tie on\na man sitting on a motor scooter on a beach\na stop sign with a black and white border and a black and white photo of\na woman is riding a motorcycle with a car\na woman riding a motorcycle down a street\na woman with long hair and a long hair\na woman with a black and white scarf holding a frisbee\na woman with a white shirt and a tie\na white foam container sitting next to a white plate\na UNK written on a ship is in the water\na dog is in the snow on a slope\na close up of a person with a hair dryer\na piece of paper with a quote on it\na woman with a white shirt and a tie\na man in a white dress shirt and tie\na woman with long hair and a hair dryer\na close up of a person wearing a shirt and tie\na woman with a UNK on her face is brushing her teeth\na woman with a tattoo on her head\na train is parked on the tracks in a train station\na train is traveling down the tracks at night\na woman with a toothbrush in her mouth\na group of people walking up a ramp on a bridge\na black and white photo of people on a boat\na couple of people sitting on a bench\na man and woman are kissing while kissing\na man holding a plaque with a picture of a UNK on it\na suitcase with a picture of a UNK on it\na suitcase sitting on the ground in front of a building\na man and woman riding on a motorcycle\na man and a woman sitting on a motorcycle\na motorcycle with graffiti written on it is parked on the street\na person riding a motorcycle with a sign on the back\na dark night with a dark background and a dark background\nExtracted 62 frames (1 frame per second).\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install sentence-transformers","metadata":{"execution":{"iopub.status.busy":"2024-04-24T06:21:26.009559Z","iopub.execute_input":"2024-04-24T06:21:26.010155Z","iopub.status.idle":"2024-04-24T06:21:38.721048Z","shell.execute_reply.started":"2024-04-24T06:21:26.010124Z","shell.execute_reply":"2024-04-24T06:21:38.720046Z"},"trusted":true},"execution_count":101,"outputs":[{"name":"stdout","text":"Collecting sentence-transformers\n  Downloading sentence_transformers-2.7.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: transformers<5.0.0,>=4.34.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.39.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.66.1)\nRequirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (2.1.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.26.4)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.11.4)\nRequirement already satisfied: huggingface-hub>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.22.2)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (9.5.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.2.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2023.12.25)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.4.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.2.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.15.1->sentence-transformers) (3.1.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\nDownloading sentence_transformers-2.7.0-py3-none-any.whl (171 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.5/171.5 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n\u001b[?25hInstalling collected packages: sentence-transformers\nSuccessfully installed sentence-transformers-2.7.0\n","output_type":"stream"}]},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\nmodel = SentenceTransformer('all-MiniLM-L6-v2', device='cuda')\nsentence_embeddings = model.encode('This is an example')","metadata":{"execution":{"iopub.status.busy":"2024-04-24T06:24:39.522753Z","iopub.execute_input":"2024-04-24T06:24:39.523108Z","iopub.status.idle":"2024-04-24T06:24:40.162536Z","shell.execute_reply.started":"2024-04-24T06:24:39.523083Z","shell.execute_reply":"2024-04-24T06:24:40.161615Z"},"trusted":true},"execution_count":105,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3bf3f2f9a4f04baab6021ebaf0d0fbca"}},"metadata":{}}]},{"cell_type":"code","source":"sentences = [\n    \"This framework generates embeddings for each input sentence\",\n    \"Sentences are passed as a list of strings.\",\n    \"The quick brown fox jumps over the lazy dog.\",\n]\n\n# Sentences are encoded by calling model.encode()\nembeddings = model.encode(sentences)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-24T06:24:40.472100Z","iopub.execute_input":"2024-04-24T06:24:40.472386Z","iopub.status.idle":"2024-04-24T06:24:40.502023Z","shell.execute_reply.started":"2024-04-24T06:24:40.472362Z","shell.execute_reply":"2024-04-24T06:24:40.501039Z"},"trusted":true},"execution_count":106,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e8c5709545354d929373613cf10a0aaf"}},"metadata":{}}]},{"cell_type":"code","source":"# Print the embeddings\nfor sentence, embedding in zip(sentences, embeddings):\n    print(\"Sentence:\", sentence)\n    print(\"Embedding:\", embedding)\n    print(\"\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}