{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 ðŸš€ 2024-4-24 Python-3.11.7 torch-2.2.2 CUDA:0 (NVIDIA A40, 45403MiB)\n",
      "\n",
      "Fusing layers... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5m summary: 290 layers, 22323858 parameters, 0 gradients, 52.6 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "# Replace 'model.pt' with the actual path to your model file\n",
    "model = torch.hub.load('yolov5', 'custom', path='yolov5m_Objects365.pt', source='local')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'video_1': {'Person': 0.9616837501525879, 'Hat': 0.9586727023124695, 'High Heels': 0.9048386812210083, 'Handbag/Satchel': 0.8986946940422058, 'Tie': 0.8888458609580994, 'Belt': 0.8234562873840332, 'Leather Shoes': 0.7883317470550537, 'Car': 0.7359131574630737, 'Sports Car': 0.5407417416572571, 'Other Shoes': 0.5004479289054871, 'Wild Bird': 0.4408917725086212, 'Ring': 0.4271615445613861, 'Book': 0.4010309875011444, 'Gloves': 0.34225064516067505, 'Glasses': 0.2980033755302429, 'Cell Phone': 0.25908422470092773}, 'video_2': {'Person': 0.9550806283950806, 'Hat': 0.9131593108177185, 'Clock': 0.7713071703910828, 'Cup': 0.7681269645690918, 'Helmet': 0.751285195350647, 'Tie': 0.7476629018783569, 'Glasses': 0.7330009341239929, 'Airplane': 0.6994612216949463, 'Horse': 0.5765413641929626, 'Lamp': 0.5695498585700989, 'Street Lights': 0.5459650158882141, 'Drum': 0.5176036953926086, 'Leather Shoes': 0.5149014592170715, 'Candle': 0.4996538758277893, 'Boots': 0.48709529638290405, 'Umbrella': 0.48274746537208557, 'SUV': 0.42752546072006226, 'Bench': 0.4072531759738922, 'Other Shoes': 0.3990471363067627, 'Sneakers': 0.39439424872398376, 'Dog': 0.37575939297676086, 'Pickup Truck': 0.36796557903289795, 'Wine Glass': 0.36734071373939514, 'Bracelet': 0.35611820220947266, 'Belt': 0.3476501405239105, 'Plate': 0.33486610651016235, 'Train': 0.31472471356391907, 'Truck': 0.2962164878845215, 'Desk': 0.28443577885627747, 'Handbag/Satchel': 0.27701324224472046, 'Gloves': 0.2745983600616455, 'Gun': 0.26115721464157104, 'Mask': 0.2583197355270386, 'Car': 0.2525121569633484, 'Bottle': 0.2521887421607971}, 'video_3': {'Person': 0.943314790725708, 'Tie': 0.8474473357200623, 'Gloves': 0.6791850328445435, 'Cup': 0.4410810172557831, 'Wild Bird': 0.3503154218196869, 'Other Shoes': 0.3178614675998688, 'Boots': 0.3021405041217804, 'Glasses': 0.2836189270019531, 'Bracelet': 0.2669355571269989}, 'video_4': {'Lamp': 0.8905339241027832, 'Bottle': 0.8746991157531738, 'Person': 0.8641454577445984, 'Handbag/Satchel': 0.814554750919342, 'Flower': 0.7576295137405396, 'Hat': 0.6527922749519348, 'Desk': 0.634272575378418, 'Cup': 0.598196268081665, 'Chair': 0.5781320929527283, 'Bracelet': 0.5176048278808594, 'Napkin': 0.3509172201156616, 'Pillow': 0.3238091766834259}, 'video_5': {'Wine Glass': 0.9199656844139099, 'Cup': 0.9069517254829407, 'Drum': 0.7607412934303284, 'Person': 0.7160702347755432, 'Bottle': 0.6798928380012512, 'Boat': 0.6364712119102478, 'Barrel/bucket': 0.5731148719787598, 'Sink': 0.5474429130554199, 'Trash bin Can': 0.44285494089126587, 'Bracelet': 0.34247103333473206, 'Microphone': 0.25080597400665283}, 'video_6': {'Person': 0.8718969821929932, 'Bracelet': 0.6223370432853699, 'Knife': 0.6113772988319397, 'Flower': 0.5709731578826904, 'Mirror': 0.5276419520378113, 'Bowl/Basin': 0.4500599205493927, 'Bottle': 0.4419497847557068, 'Desk': 0.43828442692756653, 'Hat': 0.36487600207328796, 'Belt': 0.3486121892929077, 'Glasses': 0.3413391709327698, 'Potted Plant': 0.33455803990364075, 'Handbag/Satchel': 0.3008570373058319, 'Flag': 0.2799239754676819, 'Picture/Frame': 0.2740265429019928}, 'video_7': {'Hat': 0.8883181214332581, 'Person': 0.7785103917121887, 'Lamp': 0.6401374340057373, 'Car': 0.605605959892273, 'Ladder': 0.5258789658546448, 'Pickup Truck': 0.3198150396347046, 'Ring': 0.3194440007209778, 'Bracelet': 0.26686665415763855}, 'video_8': {'Person': 0.9534221291542053, 'Drum': 0.695809543132782, 'Car': 0.48466023802757263, 'Pickup Truck': 0.4665926992893219, 'Necklace': 0.4268440902233124, 'Chair': 0.36326804757118225, 'Bracelet': 0.2816696763038635, 'Other Shoes': 0.2657870650291443, 'Bus': 0.2643898129463196}, 'video_9': {'Person': 0.9477751851081848, 'Tie': 0.9206235408782959, 'Belt': 0.7977558374404907, 'Barrel/bucket': 0.797275960445404, 'Cup': 0.7366628646850586, 'Hat': 0.7058953642845154, 'Desk': 0.6722179651260376, 'Plate': 0.5934373736381531, 'Gloves': 0.5836461782455444, 'Helmet': 0.5626147985458374, 'Other Shoes': 0.4565727412700653, 'Watch': 0.4399324357509613, 'Car': 0.4391753375530243, 'Glasses': 0.4195846617221832, 'Sneakers': 0.2809889614582062, 'Bracelet': 0.26195764541625977, 'Bench': 0.252565860748291}, 'video_10': {'Person': 0.9629771709442139, 'Tie': 0.8964803218841553, 'Plate': 0.8696210980415344, 'Picture/Frame': 0.8122268319129944, 'Necklace': 0.803977370262146, 'Cup': 0.7615143656730652, 'High Heels': 0.7214057445526123, 'Bottle': 0.7184330821037292, 'Leather Shoes': 0.6915642619132996, 'Pillow': 0.6858599185943604, 'Desk': 0.6817103028297424, 'Chair': 0.6184738874435425, 'Coffee Table': 0.610129177570343, 'Couch': 0.48095181584358215, 'Side Table': 0.44646331667900085, 'Lamp': 0.439729779958725, 'Hat': 0.33811748027801514, 'Other Shoes': 0.32608917355537415, 'Traffic Sign': 0.30093082785606384, 'Book': 0.29633212089538574, 'Cell Phone': 0.29426109790802, 'Jug': 0.2745181620121002}, 'video_11': {'Person': 0.8975805640220642, 'Airplane': 0.8511996269226074, 'Hat': 0.7735760807991028, 'Car': 0.7627253532409668, 'Boots': 0.6825770139694214, 'Horse': 0.6808226108551025, 'Bus': 0.4636562466621399, 'Monitor/TV': 0.4381248950958252, 'Bow Tie': 0.38992077112197876, 'Belt': 0.38546571135520935, 'Dog': 0.3822185695171356, 'Other Shoes': 0.3727787435054779, 'Pickup Truck': 0.345793753862381, 'Helmet': 0.34269437193870544, 'Glasses': 0.31527745723724365, 'Tie': 0.29752257466316223, 'Bench': 0.29495641589164734, 'Bracelet': 0.2709670960903168, 'Faucet': 0.2622697353363037, 'Storage box': 0.25733116269111633, 'Gloves': 0.2546180188655853, 'Cymbal': 0.25382035970687866}}\n"
     ]
    }
   ],
   "source": [
    "model_name = \"yolo5\"\n",
    "results = {}\n",
    "for folders in os.listdir(f'data/frames'):\n",
    "    output_directory = f'data/results/{model_name}/{folders}'\n",
    "    if not os.path.exists(output_directory):\n",
    "        os.makedirs(output_directory)\n",
    "    predictions = {}\n",
    "    folder_path = os.path.join('data/frames', folders)\n",
    "    for j, file in enumerate(os.listdir(folder_path)):\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        frame = cv2.imread(file_path)\n",
    "        height, width, channels = frame.shape\n",
    "\n",
    "        # Detecting objects\n",
    "        res = model(frame)\n",
    "        # Initialize dictionary for this frame\n",
    "        prediction = {}\n",
    "\n",
    "        for d in res.pandas().xyxy[0].to_dict(orient=\"records\"):\n",
    "            # Extract class and confidence\n",
    "            class_name = d[\"name\"]\n",
    "            confidence = d[\"confidence\"]\n",
    "\n",
    "            # Extract bounding box coordinates\n",
    "            x1 = int(d[\"xmin\"])\n",
    "            y1 = int(d[\"ymin\"])\n",
    "            x2 = int(d[\"xmax\"])\n",
    "            y2 = int(d[\"ymax\"])\n",
    "\n",
    "            # Draw bounding box\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f\"{class_name} {confidence:.2f}\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36, 255, 12), 2)\n",
    "            # Store prediction in dictionary\n",
    "            prediction[class_name] = confidence\n",
    "\n",
    "\n",
    "        # Save the annotated frame\n",
    "        annotated_frame_path = os.path.join(output_directory, f\"result_{j}.jpg\")\n",
    "        cv2.imwrite(annotated_frame_path, frame)\n",
    "\n",
    "        # Store frame info in the predictions dictionary\n",
    "        for k in prediction.keys():\n",
    "            if k in predictions:\n",
    "                predictions[k] = max(predictions[k], prediction[k])\n",
    "            else:\n",
    "                predictions[k] = prediction[k]\n",
    "\n",
    "    # Store predictions in the results dictionary\n",
    "    predictions = dict(sorted(predictions.items(), key=lambda item: item[1], reverse=True))\n",
    "    results[folders] = predictions\n",
    "    \n",
    "    with open(f\"{output_directory}/results.txt\", \"w\") as f:\n",
    "        for key in predictions:\n",
    "            f.write(f\"{key}: {predictions[key]}\\n\")\n",
    "\n",
    "# Save the results dictionary to a file\n",
    "output_file = f\"{model_name}/results.json\"\n",
    "\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
